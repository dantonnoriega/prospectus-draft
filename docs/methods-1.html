<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>DRAFT Dissertation Prospectus</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="DRAFT Dissertation Prospectus">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="DRAFT Dissertation Prospectus" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="DRAFT Dissertation Prospectus" />
  
  
  

<meta name="author" content="Danton Noriega">


<meta name="date" content="2017-02-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="set-up-text.html">
<link rel="next" href="chapter-2.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>

\(
\newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
\)

  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Noriega Prospectus</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Dissertation Overview</a></li>
<li class="chapter" data-level="1" data-path="chapter-1.html"><a href="chapter-1.html"><i class="fa fa-check"></i><b>1</b> An Evaluation of the Double Up Food Bucks program</a></li>
<li class="chapter" data-level="2" data-path="placeholder.html"><a href="placeholder.html"><i class="fa fa-check"></i><b>2</b> Placeholder</a></li>
<li class="chapter" data-level="3" data-path="placeholder-1.html"><a href="placeholder-1.html"><i class="fa fa-check"></i><b>3</b> Placeholder</a></li>
<li class="chapter" data-level="4" data-path="set-up-text.html"><a href="set-up-text.html"><i class="fa fa-check"></i><b>4</b> set up text</a><ul>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html"><i class="fa fa-check"></i>Methods</a><ul>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#set-up"><i class="fa fa-check"></i>Set up</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#literature-reviews"><i class="fa fa-check"></i>Literature Reviews</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#ols-frameworks"><i class="fa fa-check"></i>OLS Frameworks</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#difference-in-differences-in-differences-dd-pseudo-panel"><i class="fa fa-check"></i>Difference-in-Differences-in-Differences (DD) Pseudo-Panel</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#secondary-analysis-regression-discontinuity-rd"><i class="fa fa-check"></i>Secondary Analysis: Regression Discontinuity (RD)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-2.html"><a href="chapter-2.html"><i class="fa fa-check"></i><b>5</b> Non-recurrent TANF spending in Durham County</a></li>
<li class="chapter" data-level="6" data-path="placeholder-2.html"><a href="placeholder-2.html"><i class="fa fa-check"></i><b>6</b> Placeholder</a></li>
<li class="chapter" data-level="7" data-path="placeholder-3.html"><a href="placeholder-3.html"><i class="fa fa-check"></i><b>7</b> Placeholder</a></li>
<li class="chapter" data-level="8" data-path="placeholder-4.html"><a href="placeholder-4.html"><i class="fa fa-check"></i><b>8</b> Placeholder</a></li>
<li class="chapter" data-level="9" data-path="costumer-segmentation-of-snap-shoppers.html"><a href="costumer-segmentation-of-snap-shoppers.html"><i class="fa fa-check"></i><b>9</b> Costumer Segmentation of SNAP Shoppers</a></li>
<li class="chapter" data-level="10" data-path="placeholder-5.html"><a href="placeholder-5.html"><i class="fa fa-check"></i><b>10</b> Placeholder</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DRAFT Dissertation Prospectus</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods-1" class="section level2 unnumbered">
<h2>Methods</h2>
<div id="set-up" class="section level3 unnumbered">
<h3>Set up</h3>
<p>Recall the research question of interest—whether the DUFB incentive increases spending on fresh fruits and vegetables (FV) within stores participating in the program. The outcome variable, in this case, is total spending on FV.</p>
<p>I’ve considered other possible values for the outcome variable. For example, the proportion of dollars spent per transaction or the total ounces of FV purchased. Each added an extra layer of complication. Using proportion of expenditure per given transaction would vary wildly, particularly with small transactions, and would creating two mass points at zero and one (no FV purchased and only FV purchased). Total ounces depends on the variable and quality of the data. I cannot be sure the data received will contain counts or ounces for fresh fruits. Fresh fruits generally do not have UPC values. Dollars spent (expenditures) on FV gets to the heart of the question and is the data guaranteed to be in the data.</p>
<p>Unfortunately, using the total expenditure of FV is complicated by 3 problems.</p>
<ol style="list-style-type: decimal">
<li>Purchases not linked to customers.</li>
<li>Outcome Variable with non-trivial amount of zeros (corner solutions).</li>
<li>Consumers maximize across multiple product types.</li>
</ol>
<p>The first problem is not specific to the outcome variable. The inability to link purchases to individuals means I cannot use Panel Data Methods at the customer level; I will be unable to look at how customers behavior changes over-time and cannot control for unobserved customer heterogeneity. I’m instead limited to modeling repeated cross-sections over-time with store-level fixed effects.</p>
<p>The second and third problems are directly related to the preferred outcome variable. I anticipate a non-trivial amount of zeros because I expect to observed a large fraction of transaction where no FVs are never purchased. Likewise, FV expenditures are often a part of a basket of goods. Just as I anticipate a non-trivial amount of zeros, I also anticipate that FVs are not purchased independently of other goods. When spending their money, consumers optimize expenditure across a large set of options. This optimization is also complicated by the first problem (cannot link) but I will go into more details later.</p>
</div>
<div id="literature-reviews" class="section level3 unnumbered">
<h3>Literature Reviews</h3>
<p><strong>Pooled Cross-Sectional Methods</strong></p>
<p><strong>Pseudo-Panel Data (Not sure about this)</strong></p>
<p><span class="citation">Verbeek (<a href="#ref-verbeek_pseudo-panels_2008">2008</a>)</span> summarizes the pioneering work of <span class="citation">Deaton (<a href="#ref-deaton_panel_1985">1985</a>)</span> and <span class="citation">(<span class="citeproc-not-found" data-reference-id="moffitt_identification_1993"><strong>???</strong></span>)</span>, both of whom contruct “pseudo-panel” data from repeated cross-sections to produce consistent population estimates. The underlying method is to break repeated cross-sections of observations into time-invariant groups, whereby averaging over observations in each group allows for consistent estimation of fixed-effects models using OLS. This is a middle ground between methods for panel data and methods for pooled cross-section. In other words, it is a second-best OLS alternative given I cannot link purchases to invididuals but I can still link purchases to stores.</p>
<p>My fear, however, is that pooled cross-sectional or pseudo-panel data structure set up for OLS estimation—which solves the first problem—bulldoze through the second and third problems. I think it is prudent to consider consumer choice behavior and the mechanisms that generate zero-expenditures. Numerous demand models exists for cross-sectional data that, with a few assumptions (like each transaction represents a distinct individual), could better estimate the impact of the DUFB incentive than straight OLS.</p>
<p>There is a vast literature on consumer purchasing behavior aka choice models (see <span class="citation">Train (<a href="#ref-train_discrete_2009">2009</a>)</span> for an introductory overview). Multiple-discrete choice models, in particular, have become popular given the increased availability of transaction-level (scanner) data <span class="citation">(Dubé <a href="#ref-dube_multiple_2004">2004</a>; Hendel <a href="#ref-hendel_estimating_1999">1999</a>)</span>. Multiple-discrete choice models, however, are too product-specific. It is not important for me to model which brand and quality of bananas or carrots were purchased. What is important to me is how much was spent on bananas, carrots, and other fruits and vegetable types versus other non-FV types. Remember, my outcome variable is expenditure on <em>total</em> FV spending. I’m far more concerned about whether or not consumers are observed buying <em>any</em> FV than I am with the exact types. That said, expenditure on non-FV is also important. <em>Therefore, what is needed are model framework flexible enough to handle a continuous outcome variable with a non-trivial amount of zeros (corner solutions) and multiple types of goods.</em></p>
<p><strong>Continuous Outcome Variables and Corner Solutions</strong></p>
<p>Corner solutions for expenditures—a continuous variable—can occur for various reasons. <span class="citation">Pudney (<a href="#ref-pudney_modelling_1989">1989</a>)</span> covers three of the most likely mechanisms producing “true” zeros in cross-sectional data. The first is that the data was gathered in too short a period of time for the purchase to occur. This problem is far more common in cross-sectional data of infrequently purchased goods (i.e. durable goods like cars or refrigerators). The second is due to a supply side factor the customer has no control over. For example, there could be a shortage of FVs or none are available. Imagine searching for FV purchases in collection of convenience store data. Many zeros would exists because some convenience stores do not sell FVs. The third zero results from a customer’s decision as a function of prices, preferences, and income constraints. A zero is perhaps observed because FVs are too expensive and the customer can get larger quantities of other, equally or more preferred, foods for the same price.</p>
<p>I expect first mechanism could apply to food purchases under specific circumstances. If data are left disaggregated or the period of observation is shrunk substantially, zeros for FVs will exists due to infrequency of purchase. For example, customers that make frequent trips to the store may not always buy FVs. A cross-section of data from one day may have a non-zero FV value for the customer but zero the next. The third mechanism applies very naturally to the grocery store environment (classical utility theory). The second will require further verification. I do not expect to find out that there were shortages of FVs in the stores observed, but I could be wrong.</p>
<p><span class="citation">Humphreys (<a href="#ref-humphreys_dealing_2013">2013</a>)</span> and <span class="citation">Carlevaro et al. (<a href="#ref-carlevaro_multiple_2016">2016</a>)</span> discuss cross sectional models that accommodate corner solutions—Tobit, <em>Two-Part</em>, and <em>Hurdle</em> models, specifically.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> The classic “corner solution” regression model is the Tobit model. Corner solutions are utility maximizing and no assumptions are made about the decision not to purchase/consume. In contrast to the Tobit model, the decision to participate in consumption is explicitly formulated in the Two-Part and Hurdle models. Participation is the “first hurdle”, the amount purchased/consumed is the “second hurdle”.</p>
<p>In the Two-Part model, the decision to buy is estimate separately and sequentially from how much (amount) to buy; Probit is used to estimate the decision-to-buy process and OLS is used to estimate the amount purchased. The Double Hurdle model estimates both these decision simultaneously via maximum likelihood. The “full” Double Hurdle model allows for correlation between the error terms in the decision and amount/consumption equations <span class="citation">(Jones <a href="#ref-jones_note_1992">1992</a>)</span>. Imposing the assumption that unobservable factors between the decision and amount decisions are uncorrelated reduces the “full” Double Hurdle to the “Cragg” model <span class="citation">(Cragg <a href="#ref-cragg_statistical_1971">1971</a>)</span>.</p>
<p>It is unclear to me if Two-Part or the Double Hurdle models that formalize “participation” are necessary when considering FV purchases. This makes more intuitive sense for something like cigarette or alcohol consumption, where zero-expenditure can be the result of abstention or price/income constraints.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> There are, after all, consumers who will never consume cigarettes or alcohol, even if free (abstention). But I’m not sure if an abstention mechanism is reasonable when considering FV purchases. Do consumers really opt out (or abstain) form buying FVs altogether?</p>
<p>An infrequency of purchase mechanism for FVs, however, seems more reasonable. <span class="citation">Deaton and Irish (<a href="#ref-deaton_statistical_1984">1984</a>)</span> introduced this mechanism as an expansion to the Tobit model. This Double Hurdle has been used to model infrequent purchases of butter, pork, and prepared meals <span class="citation">(S. T. Yen and Su <a href="#ref-yen_modeling_1995">1995</a>; S. J. Su and Yen <a href="#ref-su_microeconometric_1996">1996</a>; Newman, Henchion, and Matthews <a href="#ref-newman_double-hurdle_2003">2003</a>)</span>. I find it reasonable to expect that, for any given daily cross-section of data, some of the zeros observed will be due to infrequent purchase of FVs.</p>
<p><strong>Multiple Goods</strong></p>
<p>The limitation of Tobit and other hurdle models is the estimated demand of a single good. Ideally, expenditure on different types of goods better captures the decisions and purchasing behavior of customers within a grocery store. That is, instead of collapsing all expenditure on FVs into one outcome variable, the model would allow for customers to optimize across <em>multiple</em> goods of different types, while also allowing corner solutions. Multiple discrete choice models allow the purchase of multiple types of goods, but do not capture the intensive margin (the amount) of the good purchase/consumed.</p>
<p><span class="citation">Dubin and McFadden (<a href="#ref-dubin_econometric_1984">1984</a>)</span> construct a <em>discrete-continuous</em> model were consumers can select from multiple goods/options but that they are mutually exclusive, perfect substitutes. The <em>discrete</em> component of the model captures the decision to buy a non-zero amount; the <em>continuous</em> part captures the amount purchased/consumed/utility acquired. The mutually exclusive, perfect substitute condition, however, means that one cannot be observed buying/consuming more than one good/option.</p>
<p>For any observed trip to the store, zero-expenditure in FV implies non-zero expenditure for some non-FV. Ignoring this seems unwise and I plan, at a minimum, to implement a model optimize along two dimensions—FV and non-FV. The best model I’ve found is the <em>multiple</em> discrete-continuous model extreme value (MDCEV) model introduced by <span class="citation">Bhat (<a href="#ref-bhat_multiple_2005">2005</a>)</span>. MDCEV is an extension of the Kuhn-Tucker based model developed by <span class="citation">Wales and Woodland (<a href="#ref-wales_estimation_1983">1983</a>)</span>. MDCEV allows non-zero consumption across multiple goods. <span class="citation">Kim, Allenby, and Rossi (<a href="#ref-kim_modeling_2002">2002</a>)</span> solved the intractability of the <span class="citation">Wales and Woodland (<a href="#ref-wales_estimation_1983">1983</a>)</span> model. <span class="citation">Bhat (<a href="#ref-bhat_multiple_2005">2005</a>)</span> simplified both to be more realistically applicable.</p>
<p>In the next subsection, I will formally introduce the different modeling structures I intend to use in my paper. I will first introduce the basic framework had I expected OLS to be sufficient. I then expand from OLS to Tobit and other Hurdle models before expanding into the more complex MDCEV model. The share goal, across all models, is the best possible measurement of the impact the DUFB incentive has on fruit and vegetable expenditures between participating and non-participating stores.</p>
</div>
<div id="ols-frameworks" class="section level3 unnumbered">
<h3>OLS Frameworks</h3>
<p>I want to measure the difference in SNAP EBT dollars being spent or redeemed on fresh produce. If the incentive is working, then I should see in increase in SNAP EBT dollars spending on fresh produce within stores implementing the DUFB incentive. I do not think it is enough to assume the DUFB incentive, if effective, will be measureable without considering heterogeneity. That is, if a store’s implementation of DUFB affects individual behavior, the effect could be hard to measure if measured across the entire distribution of FV purchases, instead of the subset of SNAP EBT dollars spent.</p>
<p>The Difference-in-Differences-in-Differences (DDD) regression is a fitting framework if I expect the SNAP population patroning DUFB stores to be systematically different from the SNAP population patroning the control stores. Differencing along time, treatment assignment group, and the observed SNAP transactions will reasonably account for most of the bias.</p>
<p>This is unfortunately complicated given that I cannot link transaction to individuals. I cannot determine which transactions belong to SNAP participants. The only thing I can tell is that a purchase was made with SNAP EBT dollars or that it redeemed DUFB points. I will use either a “pseudo-panel” of repeated cross-section or stick to cross-sectional methods with time effects <span class="citation">(Deaton <a href="#ref-deaton_panel_1985">1985</a>; Verbeek <a href="#ref-verbeek_pseudo-panels_2008">2008</a>)</span>.</p>
</div>
<div id="difference-in-differences-in-differences-dd-pseudo-panel" class="section level3 unnumbered">
<h3>Difference-in-Differences-in-Differences (DD) Pseudo-Panel</h3>
<p>Assume it is possible to observed individual <span class="math inline">\(i\)</span> purchasing goods across <span class="math inline">\(t=1,...,T\)</span> days. Let <span class="math inline">\(y_{it}\)</span> be total FV expenditures for individual <span class="math inline">\(i\)</span> from day <span class="math inline">\(t\)</span>. The DD regression is</p>
<p><span class="math display">\[
y_{ijt} = \gamma_i + \lambda_t + \delta D_{it} + \bm{x&#39;_{ijt} \beta} + \epsilon_{ijt}
\]</span></p>
<p>where <span class="math inline">\(\gamma_i\)</span> are individual fixed-effects, <span class="math inline">\(\lambda_t\)</span> capture daily (time) effects, <span class="math inline">\(D_{it}\)</span> indicates individual <span class="math inline">\(i\)</span>’s’ participation in DUFB on day <span class="math inline">\(t\)</span>, and <span class="math inline">\(\bm{x&#39;_{it}}\)</span> is a vector of observable characteristics about individual <span class="math inline">\(i\)</span>’s transaction on day <span class="math inline">\(t\)</span>. Idiosyncratic errors are represented by <span class="math inline">\(\epsilon_{it}\)</span> and assumed orthogonal to <span class="math inline">\(\bm{x&#39;_{it}}\)</span> (i.e. <span class="math inline">\(E[x&#39;_{it}u_{it}] = 0\)</span>).</p>
<p>Of course, I do not observed individuals, only transactions. Also, more often than not, the same individual would likely observed sporadically within in a given month. That is, were this to be panel data gathered daily from the same <span class="math inline">\(N\)</span> individuals, many of those days would have missing data.</p>
<p>Let’s instead think of each day of observed data as a single independent cross-section of <span class="math inline">\(K\)</span> transactions generated by an unknown <span class="math inline">\(N \le K\)</span> individuals across <span class="math inline">\(J\)</span> many stores. Aligned sequentially, these form a repeated cross-sections known as a “pseudo-panel”. Each transaction also falls naturally into a grouping structure—the store where it occurred—that is time-invariant, determined prior to the data being collected, and unaffected by treatment status.</p>
<p>This fits the set up for a pseudo-panel data structure introduced by <span class="citation">Deaton (<a href="#ref-deaton_panel_1985">1985</a>)</span>, where he shows consistent estimation of <span class="math inline">\(\beta\)</span> (and <span class="math inline">\(\delta\)</span>) is possible via grouping. In this case, one aggregates over all observed transactions to the store <span class="math inline">\(j\)</span> level, creating a pseudo-panel. The model then becomes</p>
<p><span class="math display">\[
\bar{y}_{jt} = \gamma_j + \lambda_t + \delta D_{jt} + \bm{\bar{x}&#39;_{jt}} {\beta} + \bar{\epsilon}_{jt}, \; j = 1,...,J; \; t=1,...,T
\]</span></p>
<p>where <span class="math inline">\(\bar{y}_{jt}\)</span> is the average of all observed fruit and vegetable expenditures <span class="math inline">\(y_{it}\)</span> in store <span class="math inline">\(j\)</span> in day <span class="math inline">\(t\)</span>. Likewise for <span class="math inline">\(\bm{\bar{x}&#39;_{jt}}\)</span>. <span class="math inline">\(\lambda_t\)</span> is unaffected and <span class="math inline">\(\sum_{i \in Store_j} D_{it}}\)</span> collapses to <span class="math inline">\(D_{jt}\)</span>. <span class="citation">Verbeek (<a href="#ref-verbeek_pseudo-panels_2008">2008</a>)</span> suggest is reasonable to assume <span class="math inline">\(\gamma_i\)</span> collapses to <span class="math inline">\(\gamma_j\)</span> if the number of individuals (transactions) in each group (store) is large. This is more than reasonable given the hundreds to thousands of transactions observed in each store per day.</p>
<p>Note that <span class="math inline">\(\gamma_j\)</span> captures all time-invariant store-level characteristics. This includes the assignment group. The daily effect <span class="math inline">\(\gamma_t\)</span> are included given the amount of data captured at the daily level. I anticipate day-of-the-week and week-of-the-month to matter when analyzing purchasing behavior. <span class="math inline">\(\bm{\bar x&#39;_{jt}}\)</span> represents the average characteristics</p>
<hr />
<p><strong>!!BELOW HERE BE DRAGONS (SUPER WORK IN PROGRESS)!!</strong></p>
</div>
<div id="secondary-analysis-regression-discontinuity-rd" class="section level3 unnumbered">
<h3>Secondary Analysis: Regression Discontinuity (RD)</h3>
<p>In the <a href="#store-selection-1">Store Selection</a> section, I discussed the construction of the score function <span class="math inline">\(\bm{s} = \widehat{P(\mathbf{D} = 1 | \bm{X}, \bm{N})}\)</span>. Given <span class="math inline">\(i = 1,...,n\)</span> stores, the score of each store can be determined via observable data, <span class="math inline">\(s_i = \widehat{P(D_i = 1|\bm{x}_i, n_i)}\)</span>. These scores, when ordered, produced perfect separation between treatment stores and control stores (see Figure <a href="methods-1.html#fig:score-plot2">4.1</a>).</p>
<p>An RD design requires a <em>running variable</em> where, above some value <span class="math inline">\(c\)</span>, the probability of being assigned to the treatment group is <span class="math inline">\(1\)</span>. Assume I make the score function <span class="math inline">\(\bm{s}\)</span> my running variable such that <span class="math inline">\(D_i = \bm{1}[s_i \ge c]\)</span>.</p>
<p>In my case, assignment <span class="math inline">\(D_i\)</span> is determined by <span class="math inline">\(s_i\)</span> by construction. Recall that <span class="math inline">\(s_i\)</span> is a function estimated on observable covariates. These are the same observable covariates the company used to determine assignment for a subset of stores. I used a linear probability model to estimate the score function and the estimated model perfectly predicted assignment. I then ordered stores by their score value and selected the next 12 unassigned stores.</p>
<p>This problem is that I do not actually know <span class="math inline">\(c\)</span>. I only know that <span class="math inline">\(c \in (0.50, 0.64)\)</span>. The light gray band in Figure <a href="methods-1.html#fig:score-plot2">4.1</a> displays the possible values of <span class="math inline">\(c\)</span>. The problem, in essence, is that I do not have—and never will have—enough stores, so I’m lacking density around where the separation occurs.</p>
<div class="figure"><span id="fig:score-plot2"></span>
<img src="noriega-prospectus-draft_files/figure-html/score-plot2-1.png" alt="Store Score vs Double Up Assignment with Uncertainty Band (light gray)"  />
<p class="caption">
FIGURE 4.1: Store Score vs Double Up Assignment with Uncertainty Band (light gray)
</p>
</div>
<p>I propose to estimate the RD design using various values of <span class="math inline">\(c\)</span>. The perpetual gap means any model estimate to the left or right of some <span class="math inline">\(c_0 \in (0.50, 0.64)\)</span> will have to be extrapolated up to <span class="math inline">\(c_0\)</span>.</p>
<p><strong>Set-up</strong></p>
<p>The outcome of variable for each store will be the <em>average amount spent on locally grown produce in a SNAP transaction per day</em>. The timeframe will be August - December (months <span class="math inline">\(8\)</span> - <span class="math inline">\(12\)</span>) of 2016, when the DUFB incentive is place. I decided on using days as the unit of observation to increase the sample amount of data for estimating. I expect there to be enough transactions per day for this to be possible.</p>
<p>Let <span class="math inline">\(y_{i}\)</span> represent the outcome variable where <span class="math inline">\(i=1,...,n\)</span> denotes stores. Let <span class="math inline">\(c\)</span> denote the cutoff; <span class="math inline">\(s_i\)</span> the score computed for store <span class="math inline">\(i\)</span>; and <span class="math inline">\(D_i\)</span> the assignment variable. Each draw (or row) of data for store <span class="math inline">\(i\)</span> is a vector <span class="math inline">\((y_i, s_i, D_i)\)</span> corresponding to a single day. Recall that <span class="math inline">\(y_i\)</span> is a point statistics estimated using a single days worth of transaction data for store <span class="math inline">\(i\)</span>. All days will be pooled, creating roughly <span class="math inline">\(30\times5=150\)</span> observations (days) per store.</p>
<p>Let <span class="math inline">\(u_i\)</span> be an error term assumed to be <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span>.</p>
<p>The RD model I propose is as follows</p>
<p><span class="math display">\[
y_{i} = \alpha + \rho D_i + \gamma (s_i - c) + \delta D_i(s_i - c) + u_{i}
\]</span></p>
<p>My hope is to produce a graph that looks like the following</p>
<p>[GENERATE EXAMPLE GRAPH. At each point <span class="math inline">\(s_i\)</span>, there will be about 150 points drawn in vertical like. This would help visualize the distribution of average-dollars-per-day.]</p>

</div>
</div>
<!-- </div> -->
<h3> Placeholder</h3>
<div id="refs" class="references">
<div id="ref-verbeek_pseudo-panels_2008">
<p>Verbeek, Marno. 2008. “Pseudo-Panels and Repeated Cross-Sections.” <em>The Econometrics of Panel Data: Fundamentals and Recent Developments in Theory and Practice</em> 46: 369.</p>
</div>
<div id="ref-deaton_panel_1985">
<p>Deaton, Angus. 1985. “Panel Data from Time Series of Cross-Sections.” <em>Journal of Econometrics</em> 30 (1): 109–26. doi:<a href="https://doi.org/10.1016/0304-4076(85)90134-4">10.1016/0304-4076(85)90134-4</a>.</p>
</div>
<div id="ref-train_discrete_2009">
<p>Train, Kenneth E. 2009. <em>Discrete Choice Methods with Simulation</em>. Cambridge university press.</p>
</div>
<div id="ref-dube_multiple_2004">
<p>Dubé, Jean-Pierre. 2004. “Multiple Discreteness and Product Differentiation: Demand for Carbonated Soft Drinks.” <em>Marketing Science</em> 23 (1): 66–81.</p>
</div>
<div id="ref-hendel_estimating_1999">
<p>Hendel, Igal. 1999. “Estimating Multiple-Discrete Choice Models: An Application to Computerization Returns.” <em>Review of Economic Studies</em> 66 (2): 423–46.</p>
</div>
<div id="ref-pudney_modelling_1989">
<p>Pudney, Stephen. 1989. “Modelling Individual Choice: The Econometrics of Corners, Kinks and Holes.”</p>
</div>
<div id="ref-humphreys_dealing_2013">
<p>Humphreys, Brad R. 2013. “Dealing with Zeros in Economic Data.” <em>Department of Economics, University of Alberta, Alberta</em>.</p>
</div>
<div id="ref-carlevaro_multiple_2016">
<p>Carlevaro, Fabrizio, Universite ' De Genève, Yves Croissant, and Universite ' De La Réunion. 2016. “Multiple Hurdle Tobit Models in R: The Mhurdle Package.”</p>
</div>
<div id="ref-jones_note_1992">
<p>Jones, Andrew M. 1992. “A Note on Computation of the Double-Hurdle Model with Dependence with an Application to Tobacco Expenditure.” <em>Bulletin of Economic Research</em> 44 (1): 67–74. doi:<a href="https://doi.org/10.1111/\%28ISSN\%291467-8586/issues">10.1111/\%28ISSN\%291467-8586/issues</a>.</p>
</div>
<div id="ref-cragg_statistical_1971">
<p>Cragg, John G. 1971. “Some Statistical Models for Limited Dependent Variables with Application to the Demand for Durable Goods.” <em>Econometrica: Journal of the Econometric Society</em>, 829–44.</p>
</div>
<div id="ref-deaton_statistical_1984">
<p>Deaton, Angus, and Margaret Irish. 1984. “Statistical Models for Zero Expenditures in Household Budgets.” <em>Journal of Public Economics</em> 23 (1-2): 59–80.</p>
</div>
<div id="ref-yen_modeling_1995">
<p>Yen, S. T., and S. J. Su. 1995. “Modeling US Butter Consumption with Zero Observations.” <em>Agricultural and Resource Economics Review (USA)</em>.</p>
</div>
<div id="ref-su_microeconometric_1996">
<p>Su, Shew Jiuan, and Steven T. Yen. 1996. “Microeconometric Models of Infrequently Purchased Goods: An Application to Household Pork Consumption.” <em>Empirical Economics</em> 21 (4): 513–33. doi:<a href="https://doi.org/10.1007/BF01180699">10.1007/BF01180699</a>.</p>
</div>
<div id="ref-newman_double-hurdle_2003">
<p>Newman, Carol, Maeve Henchion, and Alan Matthews. 2003. “A Double-Hurdle Model of Irish Household Expenditure on Prepared Meals.” <em>Applied Economics</em> 35 (9): 1053–61.</p>
</div>
<div id="ref-dubin_econometric_1984">
<p>Dubin, Jeffrey A., and Daniel L. McFadden. 1984. “An Econometric Analysis of Residential Electric Appliance Holdings and Consumption.” <em>Econometrica</em> 52 (2): 345–62. doi:<a href="https://doi.org/10.2307/1911493">10.2307/1911493</a>.</p>
</div>
<div id="ref-bhat_multiple_2005">
<p>Bhat, Chandra R. 2005. “A Multiple Discretecontinuous Extreme Value Model: Formulation and Application to Discretionary Time-Use Decisions.” <em>Transportation Research Part B: Methodological</em> 39 (8): 679–707. doi:<a href="https://doi.org/10.1016/j.trb.2004.08.003">10.1016/j.trb.2004.08.003</a>.</p>
</div>
<div id="ref-wales_estimation_1983">
<p>Wales, T. J., and A. D. Woodland. 1983. “Estimation of Consumer Demand Systems with Binding Non-Negativity Constraints.” <em>Journal of Econometrics</em> 21 (3): 263–85. doi:<a href="https://doi.org/10.1016/0304-4076(83)90046-5">10.1016/0304-4076(83)90046-5</a>.</p>
</div>
<div id="ref-kim_modeling_2002">
<p>Kim, Jaehwan, Greg M. Allenby, and Peter E. Rossi. 2002. “Modeling Consumer Demand for Variety.” <em>Marketing Science</em> 21 (3): 229–50.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><span class="citation">Wooldridge (<a href="#ref-wooldridge_econometric_2010">2010</a>)</span> does not appear to differentiate between “Two-Part” models and “Hurdle” models. I will use it following <span class="citation">Humphreys (<a href="#ref-humphreys_dealing_2013">2013</a>)</span> language, which does.<a href="methods-1.html#fnref1">↩</a></p></li>
<li id="fn2"><p>See <span class="citation">García and Labeaga (<a href="#ref-garcia_alternative_1996">1996</a>)</span> and <span class="citation">Aristei, Perali, and Pieroni (<a href="#ref-aristei_cohort_2008">2008</a>)</span> for abstention-style hurdles.<a href="methods-1.html#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="set-up-text.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter-2.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["noriega-prospectus-draft.pdf", "noriega-prospectus-draft.epub", "noriega-prospectus-draft.mobi"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
