<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>DRAFT Dissertation Prospectus</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="DRAFT Dissertation Prospectus">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="DRAFT Dissertation Prospectus" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="DRAFT Dissertation Prospectus" />
  
  
  

<meta name="author" content="Danton Noriega">


<meta name="date" content="2017-03-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="store-selection-1.html">
<link rel="next" href="chapter-2.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.8/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-5.0.6/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-5.0.6/highstock.js"></script>
<script src="libs/highcharts-5.0.6/highcharts-3d.js"></script>
<script src="libs/highcharts-5.0.6/highcharts-more.js"></script>
<script src="libs/highcharts-5.0.6/modules/annotations.js"></script>
<script src="libs/highcharts-5.0.6/modules/broken-axis.js"></script>
<script src="libs/highcharts-5.0.6/modules/data.js"></script>
<script src="libs/highcharts-5.0.6/modules/drilldown.js"></script>
<script src="libs/highcharts-5.0.6/modules/exporting.js"></script>
<script src="libs/highcharts-5.0.6/modules/funnel.js"></script>
<script src="libs/highcharts-5.0.6/modules/heatmap.js"></script>
<script src="libs/highcharts-5.0.6/modules/map.js"></script>
<script src="libs/highcharts-5.0.6/modules/no-data-to-display.js"></script>
<script src="libs/highcharts-5.0.6/modules/offline-exporting.js"></script>
<script src="libs/highcharts-5.0.6/modules/solid-gauge.js"></script>
<script src="libs/highcharts-5.0.6/modules/treemap.js"></script>
<script src="libs/highcharts-5.0.6/plugins/annotations.js"></script>
<script src="libs/highcharts-5.0.6/plugins/draggable-legend.js"></script>
<script src="libs/highcharts-5.0.6/plugins/draggable-points.js"></script>
<script src="libs/highcharts-5.0.6/plugins/export-csv.js"></script>
<script src="libs/highcharts-5.0.6/plugins/grouped-categories.js"></script>
<script src="libs/highcharts-5.0.6/plugins/motion.js"></script>
<script src="libs/highcharts-5.0.6/plugins/pattern-fill-v2.js"></script>
<script src="libs/highcharts-5.0.6/plugins/tooltip-delay.js"></script>
<script src="libs/highcharts-5.0.6/custom/reset.js"></script>
<script src="libs/highcharts-5.0.6/custom/symbols-extra.js"></script>
<script src="libs/highcharts-5.0.6/custom/text-symbols.js"></script>
<link href="libs/fontawesome-4.5.0/font-awesome.min.css" rel="stylesheet" />
<link href="libs/htmlwdgtgrid-1/htmlwdgtgrid.css" rel="stylesheet" />
<script src="libs/highchart-binding-0.5.0/highchart.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>

\(
\newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
\)

  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Noriega Prospectus</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Dissertation Overview</a></li>
<li class="chapter" data-level="1" data-path="chapter-1.html"><a href="chapter-1.html"><i class="fa fa-check"></i><b>1</b> An Evaluation of the Double Up Food Bucks program</a><ul>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="concept-in-a-plot.html"><a href="concept-in-a-plot.html"><i class="fa fa-check"></i>Concept in a Plot</a></li>
<li class="chapter" data-level="" data-path="intro-1.html"><a href="intro-1.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="intro-1.html"><a href="intro-1.html#financial-incentives-to-encourage-healthy-food-purchases"><i class="fa fa-check"></i>Financial Incentives to Encourage Healthy Food Purchases</a></li>
<li class="chapter" data-level="" data-path="intro-1.html"><a href="intro-1.html#the-healthy-incentives-pilot"><i class="fa fa-check"></i>The Healthy Incentives Pilot</a></li>
<li class="chapter" data-level="" data-path="intro-1.html"><a href="intro-1.html#the-double-up-food-bucks-program"><i class="fa fa-check"></i>The Double Up Food Bucks Program</a></li>
<li class="chapter" data-level="" data-path="intro-1.html"><a href="intro-1.html#double-up-food-bucks-vs-the-healthy-incentives-pilot"><i class="fa fa-check"></i>Double Up Food Bucks vs the Healthy Incentives Pilot</a></li>
<li class="chapter" data-level="" data-path="intro-1.html"><a href="intro-1.html#evaluating-double-up-food-bucks-in-non-experimental-conditions"><i class="fa fa-check"></i>Evaluating Double Up Food Bucks in Non-experimental Conditions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-1.html"><a href="data-1.html"><i class="fa fa-check"></i>Data Description</a><ul>
<li class="chapter" data-level="" data-path="data-1.html"><a href="data-1.html#how-the-dufb-incentive-is-implemented"><i class="fa fa-check"></i>How the DUFB Incentive is Implemented</a></li>
<li class="chapter" data-level="" data-path="data-1.html"><a href="data-1.html#purchases-cannot-be-linked-to-individuals-no-loyalty-card-data"><i class="fa fa-check"></i>Purchases Cannot Be Linked to Individuals (No Loyalty Card Data)</a></li>
<li class="chapter" data-level="" data-path="data-1.html"><a href="data-1.html#dufb-incentive-inconsistency-across-years"><i class="fa fa-check"></i>DUFB Incentive Inconsistency Across Years</a></li>
<li class="chapter" data-level="" data-path="data-1.html"><a href="data-1.html#limited-dependent-variable"><i class="fa fa-check"></i>Limited Dependent Variable</a></li>
<li class="chapter" data-level="" data-path="data-1.html"><a href="data-1.html#other-information"><i class="fa fa-check"></i>Other Information</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="store-selection-1.html"><a href="store-selection-1.html"><i class="fa fa-check"></i>Overview of Store Selection and Expansion</a><ul>
<li class="chapter" data-level="" data-path="store-selection-1.html"><a href="store-selection-1.html#selection-and-expansion-of-double-up-stores"><i class="fa fa-check"></i>Selection and Expansion of Double Up Stores</a></li>
<li class="chapter" data-level="" data-path="store-selection-1.html"><a href="store-selection-1.html#expansion-on-observables"><i class="fa fa-check"></i>Expansion on Observables</a></li>
<li class="chapter" data-level="" data-path="store-selection-1.html"><a href="store-selection-1.html#selection-of-control-stores"><i class="fa fa-check"></i>Selection of Control Stores</a></li>
<li class="chapter" data-level="" data-path="store-selection-1.html"><a href="store-selection-1.html#motivation-for-matching"><i class="fa fa-check"></i>Motivation for Matching</a></li>
<li class="chapter" data-level="" data-path="store-selection-1.html"><a href="store-selection-1.html#matching-details"><i class="fa fa-check"></i>Matching Details</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html"><i class="fa fa-check"></i>Methods</a><ul>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#set-up"><i class="fa fa-check"></i>Set up</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#methods-overview"><i class="fa fa-check"></i>Methods Overview</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#difference-in-difference-in-differences-ddd"><i class="fa fa-check"></i>Difference-in-Difference-in-Differences (DDD)</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#tobit-and-other-hurdle-models"><i class="fa fa-check"></i>Tobit and other Hurdle Models</a></li>
<li class="chapter" data-level="" data-path="methods-1.html"><a href="methods-1.html#regression-discontinuity-rd"><i class="fa fa-check"></i>Regression Discontinuity (RD)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-2.html"><a href="chapter-2.html"><i class="fa fa-check"></i><b>2</b> The Durham Connects RCT and Requests for Social Services</a><ul>
<li class="chapter" data-level="" data-path="motivation-1.html"><a href="motivation-1.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="concept-in-a-plot-1.html"><a href="concept-in-a-plot-1.html"><i class="fa fa-check"></i>Concept in a Plot</a></li>
<li class="chapter" data-level="" data-path="intro-2.html"><a href="intro-2.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="intro-2.html"><a href="intro-2.html#the-durham-connects-randomized-control-trial"><i class="fa fa-check"></i>The Durham Connects Randomized Control Trial</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-2.html"><a href="data-2.html"><i class="fa fa-check"></i>Data</a><ul>
<li class="chapter" data-level="" data-path="data-2.html"><a href="data-2.html#administrative-records"><i class="fa fa-check"></i>Administrative Records</a></li>
<li class="chapter" data-level="" data-path="data-2.html"><a href="data-2.html#short-form-birth-certificate-data"><i class="fa fa-check"></i>Short-form Birth Certificate Data</a></li>
<li class="chapter" data-level="" data-path="data-2.html"><a href="data-2.html#matching-strategy"><i class="fa fa-check"></i>Matching Strategy</a></li>
<li class="chapter" data-level="" data-path="data-2.html"><a href="data-2.html#irb-and-permissions"><i class="fa fa-check"></i>IRB and Permissions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="methods-2.html"><a href="methods-2.html"><i class="fa fa-check"></i>Methods</a><ul>
<li class="chapter" data-level="" data-path="methods-2.html"><a href="methods-2.html#a-simple-model-of-social-service-demand"><i class="fa fa-check"></i>A Simple Model of Social Service Demand</a></li>
<li class="chapter" data-level="" data-path="methods-2.html"><a href="methods-2.html#analytical-framework"><i class="fa fa-check"></i>Analytical Framework</a></li>
<li class="chapter" data-level="" data-path="methods-2.html"><a href="methods-2.html#poisson-regression-model-with-pooled-data"><i class="fa fa-check"></i>Poisson Regression Model with Pooled Data</a></li>
<li class="chapter" data-level="" data-path="methods-2.html"><a href="methods-2.html#stratified-cox-proportional-hazard-model"><i class="fa fa-check"></i>Stratified Cox Proportional Hazard Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="next-steps.html"><a href="next-steps.html"><i class="fa fa-check"></i>Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-3.html"><a href="chapter-3.html"><i class="fa fa-check"></i><b>3</b> The SNAP Benefit Cycle and the Demand for Emergency Assistance</a><ul>
<li class="chapter" data-level="" data-path="motivation-2.html"><a href="motivation-2.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="concept-in-a-plot-2.html"><a href="concept-in-a-plot-2.html"><i class="fa fa-check"></i>Concept in a Plot</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="data-3.html"><a href="data-3.html"><i class="fa fa-check"></i>Data</a><ul>
<li class="chapter" data-level="" data-path="data-3.html"><a href="data-3.html#dss-data"><i class="fa fa-check"></i>DSS Data</a></li>
<li class="chapter" data-level="" data-path="data-3.html"><a href="data-3.html#food-pantry-data"><i class="fa fa-check"></i>Food Pantry Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="methods-3.html"><a href="methods-3.html"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="next-steps-1.html"><a href="next-steps-1.html"><i class="fa fa-check"></i>Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>4</b> References</a></li>
<li class="chapter" data-level="5" data-path="healthy-food-experiments-becr-project.html"><a href="healthy-food-experiments-becr-project.html"><i class="fa fa-check"></i><b>5</b> Healthy Food Experiments (BECR Project)</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DRAFT Dissertation Prospectus</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods-1" class="section level2 unnumbered">
<h2>Methods</h2>
<div id="set-up" class="section level3 unnumbered">
<h3>Set up</h3>
<p>Recall the research question of interest—whether the DUFB incentive increases spending on fresh fruits and vegetables (FV) within stores participating in the program. The outcome variable, in this case, is total spending on FV.</p>
<p>I’ve considered other possible values for the outcome variable. For example, the proportion of dollars spent per transaction or the total ounces of FV purchased. Each added an extra layer of complication. Using proportion of expenditure per given transaction would vary wildly, particularly with small transactions, and would creating two mass points at zero and one (no FV purchased and only FV purchased). Total ounces depends on the variable and quality of the data. I cannot be sure the data received will contain counts or ounces for fresh fruits. Fresh fruits generally do not have UPC values. Dollars spent (expenditures) on FV gets to the heart of the question and is the data guaranteed to be in the data.</p>
<p>Unfortunately, using the total expenditure of FV is complicated by 3 problems.</p>
<ol style="list-style-type: decimal">
<li>Purchases not linked to customers.</li>
<li>Outcome Variable with non-trivial amount of zeros (corner solutions).</li>
<li>Consumers maximize across multiple product types.</li>
</ol>
<p>The first problem is not specific to the outcome variable. The inability to link purchases to individuals means I cannot use Panel Data Methods at the customer level; I will be unable to look at how customers behavior changes over-time and cannot control for unobserved customer heterogeneity. I’m instead limited to methods for repeated cross-sections over-time.</p>
<p>The second and third problems are directly related to the preferred outcome variable. I anticipate a non-trivial amount of zeros because I expect to observed a large fraction of transaction where no FVs are never purchased. Likewise, FV expenditures are often a part of a basket of goods. Just as I anticipate a non-trivial amount of zeros, I also anticipate that FVs are not purchased independently of other goods. When spending their money, consumers optimize expenditure across a large set of options. This optimization is also complicated by the first problem (cannot link) but I will go into more details later.</p>
</div>
<div id="methods-overview" class="section level3 unnumbered">
<h3>Methods Overview</h3>
<p><strong>Difference-in-Difference-in-Differences</strong></p>
<p>I want to measure the difference in SNAP EBT dollars being spent or redeemed on fresh produce. If the incentive is working, then I should see in increase in SNAP EBT dollars spending on fresh produce within stores implementing the DUFB incentive. I do not think it is enough to assume the DUFB incentive, if effective, will be measurable without considering heterogeneity. That is, if a store’s implementation of DUFB affects individual behavior, the effect could be hard to measure if measured across the entire distribution of FV purchases, instead of the subset of SNAP EBT dollars spent.</p>
<p>The Difference-in-Difference-in-Differences (DDD) regression is a fitting framework if I expect the SNAP population that patrons DUFB (experimental) stores to be systematically different from the SNAP population that patrons the non-DUFB (non-experimental) stores.<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> Differencing along time, store experimental group, and the type of transaction (SNAP or not) will reasonably capture any systematic differences.</p>
<p>This is unfortunately complicated given that I cannot link transaction to individuals. But I can tell if a purchase was made with SNAP EBT dollars or that it redeemed DUFB points. This is enough to split transactions into SNAP/DUFB-redeemed versus other standard transactions. This provides a way of grouping to perform a DDD.</p>
<p>Any model like DDD that is estimate via OLS, however, ignores the second and third problems. I think it is prudent to consider consumer choice behavior and the mechanisms that generate zero-expenditures. Numerous demand models exists for cross-sectional data that, with a few assumptions (like each transaction represents a distinct individual), may better estimate the impact of the DUFB incentive than straight OLS.</p>
<p>There is a vast literature on consumer purchasing behavior aka choice models (see <span class="citation">Train (<a href="#ref-train_discrete_2009">2009</a>)</span> for an introductory overview). Multiple-discrete choice models, in particular, have become popular given the increased availability of transaction-level (scanner) data <span class="citation">(Dubé <a href="#ref-dube_multiple_2004">2004</a>; Hendel <a href="#ref-hendel_estimating_1999">1999</a>)</span>. Multiple-discrete choice models, however, are too product-specific. It is not important for me to model which brand and quality of bananas or carrots were purchased. What is important to me is how much was spent on bananas, carrots, and other fruits and vegetable types versus other non-FV types. Remember, my outcome variable is expenditure on <em>total</em> FV spending. I’m far more concerned about whether or not consumers are observed buying <em>any</em> FV than I am with the exact types. That said, expenditure on non-FV is also important. <em>Therefore, what is needed are model framework flexible enough to handle a continuous outcome variable with a non-trivial amount of zeros (corner solutions) and multiple types of goods.</em></p>
<p><strong>Continuous Outcome Variables and Corner Solutions</strong></p>
<p>Corner solutions for expenditures can occur for various reasons. <span class="citation">Pudney (<a href="#ref-pudney_modelling_1989">1989</a>)</span> covers three of the most likely mechanisms producing “true” zeros in cross-sectional data. The first is that the data was gathered in too short a period of time for the purchase to occur. This problem is far more common in cross-sectional data of infrequently purchased goods (i.e. durable goods like cars or refrigerators). The second is due to a supply side factor the customer has no control over. For example, there could be a shortage of FVs or none are available. Imagine searching for FV purchases in collection of convenience store data. Many zeros would exists because some convenience stores do not sell FVs. The third zero results from a customer’s decision as a function of prices, preferences, and income constraints. A zero is perhaps observed because FVs are too expensive and the customer can get larger quantities of other, equally or more preferred, foods for the same price.</p>
<p>I expect first mechanism could apply to food purchases under specific circumstances. If data are left disaggregated or the period of observation is shrunk substantially, zeros for FVs will exists due to infrequency of purchase. For example, customers that make frequent trips to the store may not always buy FVs. A cross-section of data from one day may have a non-zero FV value for the customer but zero the next. The third mechanism applies very naturally to the grocery store environment (classical utility theory). The second will require further verification. I do not expect to find out that there were shortages of FVs in the stores observed, but I could be wrong.</p>
<p><span class="citation">Humphreys (<a href="#ref-humphreys_dealing_2013">2013</a>)</span> and <span class="citation">Carlevaro et al. (<a href="#ref-carlevaro_multiple_2016">2016</a>)</span> discuss cross sectional models that accommodate corner solutions—Tobit, <em>Two-Part</em>, and <em>Hurdle</em> models, specifically.<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> The classic “corner solution” regression model is the Tobit model. Corner solutions are utility maximizing and no assumptions are made about the decision not to purchase/consume. In contrast to the Tobit model, the decision to participate in consumption is explicitly formulated in the Two-Part and Hurdle models. Participation is the “first hurdle”, the amount purchased/consumed is the “second hurdle”.</p>
<p>In the “Naive” Two-Part model, the decision to buy is estimate separately and sequentially from how much (amount) to buy; Probit is used to estimate the decision-to-buy process and OLS is used to estimate the amount purchased. The Double Hurdle model estimates both these decision simultaneously via maximum likelihood. The full Double Hurdle model allows for correlation between the error terms in the decision and amount/consumption equations <span class="citation">(Jones <a href="#ref-jones_note_1992">1992</a>)</span>. Imposing the assumption that unobservable factors between the decision and amount decisions are uncorrelated reduces the full “Jones” Double Hurdle to the “Cragg” model <span class="citation">(Cragg <a href="#ref-cragg_statistical_1971">1971</a>)</span>.</p>
<p>It is unclear to me if Two-Part or the Double Hurdle models that formalize “participation” are necessary when considering FV purchases. This makes more intuitive sense for something like cigarette or alcohol consumption, where zero-expenditure can be the result of abstention or price/income constraints.<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a> There are, after all, consumers who will never consume cigarettes or alcohol, even if free (abstention). But I’m not sure if an abstention mechanism is reasonable when considering FV purchases. Do consumers really opt out (or abstain) form buying FVs altogether?</p>
<p>An infrequency of purchase mechanism for FVs, however, seems more reasonable. <span class="citation">Deaton and Irish (<a href="#ref-deaton_statistical_1984">1984</a>)</span> introduced this mechanism as an expansion to the Tobit model. This Double Hurdle has been used to model infrequent purchases of butter, pork, and prepared meals <span class="citation">(Yen and Su <a href="#ref-yen_modeling_1995">1995</a>; Su and Yen <a href="#ref-su_microeconometric_1996">1996</a>; Newman, Henchion, and Matthews <a href="#ref-newman_double-hurdle_2003">2003</a>)</span>. I find it reasonable to expect that, for any given daily cross-section of data, some of the zeros observed will be due to infrequent purchase of FVs.</p>
<p>It’s worth noting the general increased popularity of Hurdle models as alternatives to Tobit, and other related models, like Adjusted Tobit and Heckit models. There is a long existing debate over which models perform better, with most of the criticism falling on Tobit. Monte Carlo comparison under different error distributions and exclusion restrictions find Hurdle models consistently out performing Tobit and Heckit models, both in model fit and coefficient bias <span class="citation">(Hay, Leu, and Rohrer <a href="#ref-hay_ordinary_1987">1987</a>; Manning, Duan, and Rogers <a href="#ref-manning_monte_1987">1987</a>)</span>. Monte Carlo studies have also been used to defend both approaches, encouraging a more flexible, case-by-case approach on choosing the appropriate model <span class="citation">(Leung and Yu <a href="#ref-leung_choice_1996">1996</a>; Dow and Norton <a href="#ref-dow_choosing_2003">2003</a>; Madden <a href="#ref-madden_sample_2008">2008</a>)</span>. But applied work in the applied social science, like health care expenditure and consumer purchases, generally tend to favor use of Hurdle models over Tobit or Heckit models <span class="citation">(Yen <a href="#ref-yen_working_1993">1993</a>; Smith and Brame <a href="#ref-smith_tobit_2003">2003</a>; Stewart <a href="#ref-stewart_tobit_2013">2013</a>)</span>.</p>
<p><strong>Multiple Goods</strong></p>
<p>The limitation of Tobit and other hurdle models is the estimated demand of a single good. Ideally, expenditure on different types of goods better captures the decisions and purchasing behavior of customers within a grocery store. That is, instead of collapsing all expenditure on FVs into one outcome variable, the model would allow for customers to optimize across <em>multiple</em> goods of different types, while also allowing corner solutions. Multiple discrete choice models allow the purchase of multiple types of goods, but do not capture the intensive margin (the amount) of the good purchase/consumed.</p>
<p><span class="citation">Dubin and McFadden (<a href="#ref-dubin_econometric_1984">1984</a>)</span> construct a <em>discrete-continuous</em> model were consumers can select from multiple goods/options but that they are mutually exclusive, perfect substitutes. The <em>discrete</em> component of the model captures the decision to buy a non-zero amount; the <em>continuous</em> part captures the amount purchased/consumed/utility acquired. The mutually exclusive, perfect substitute condition, however, means that one cannot be observed buying/consuming more than one good/option.</p>
<p>For any observed trip to the store, zero-expenditure in FV implies non-zero expenditure for some non-FV. Ignoring this seems unwise and I plan, at a minimum, to implement a model optimize along two dimensions—FV and non-FV. The best model I’ve found is the <em>multiple</em> discrete-continuous model extreme value (MDCEV) model introduced by <span class="citation">Bhat (<a href="#ref-bhat_multiple_2005">2005</a>)</span>. MDCEV is an extension of the Kuhn-Tucker based model developed by <span class="citation">Wales and Woodland (<a href="#ref-wales_estimation_1983">1983</a>)</span>. MDCEV allows non-zero consumption across multiple goods. <span class="citation">Kim, Allenby, and Rossi (<a href="#ref-kim_modeling_2002">2002</a>)</span> solved the intractability of the <span class="citation">Wales and Woodland (<a href="#ref-wales_estimation_1983">1983</a>)</span> model. <span class="citation">Bhat (<a href="#ref-bhat_multiple_2005">2005</a>)</span> simplified both to be more realistically applicable.</p>
<p>In the next subsection, I will formally introduce the different modeling structures I intend to use in my paper. I will first introduce the DDD framework were estimation via OLS is sufficient. I then expand from OLS to Tobit and other Hurdle models before expanding into the more complex MDCEV model. The share goal, across all models, is the best possible measurement of the impact the DUFB incentive has on fruit and vegetable expenditures between participating and non-participating stores.</p>

<hr />
</div>
<div id="difference-in-difference-in-differences-ddd" class="section level3 unnumbered">
<h3>Difference-in-Difference-in-Differences (DDD)</h3>
<p>I observe transaction <span class="math inline">\(i=1,...,L\)</span> in store <span class="math inline">\(j=1,...,N\)</span> across <span class="math inline">\(t=1,...,T\)</span> days. Let <span class="math inline">\(y_{ijt}\)</span> be total FV expenditures for transaction <span class="math inline">\(i\)</span> in store <span class="math inline">\(j\)</span> on day <span class="math inline">\(t\)</span>. The DDD regression is</p>
<p><span class="math display">\[
\begin{aligned}
y_{ijt} &amp;= \alpha_0 + \alpha_1 dE_j + \alpha_2 dS_i  + \alpha_3 dE_j \cdot dS_i \\&amp; \quad + \theta_1 dP_t + \theta_2 dP_t \cdot dE_j + \theta_3 dP_t \cdot dS_i \\
&amp; \quad + \delta dE_j \cdot dS_i \cdot dP_t + \bm{x&#39;}_{ijt} \bm{\beta} + \lambda_t + \epsilon_{ijt}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(dE_j\)</span> represents store assignment to experimental group, <span class="math inline">\(dS_i\)</span> represents a SNAP or SNAP related transaction (target group), and <span class="math inline">\(dP_t\)</span> represent the treatment period, August - December. <span class="math inline">\(\lambda_t\)</span> captures daily (time) effects and <span class="math inline">\(\bm{x&#39;}_{ijt}\)</span> is a vector of observable characteristics about transaction <span class="math inline">\(i\)</span> in store <span class="math inline">\(j\)</span> on day <span class="math inline">\(t\)</span>. The coefficient of interest is <span class="math inline">\(\delta\)</span>. <span class="math inline">\(\epsilon_{ijt}\)</span> are idiosyncratic errors at the transaction level.</p>
<p>Again, I do not observed individuals, only transactions. Yet I think it reasonable to assume that the structure of daily transaction data more closely resembles that of repeated cross-sections than of panel data. Assuming it was possible to link individuals to purchases and build panel data. The same individual would likely observed <em>sporadically</em> within in a given month. That is, were this to be panel of the same <span class="math inline">\(N\)</span> individual shoppers across <span class="math inline">\(T\)</span> total days, many—if not most—of those days would have missing data. There would certainly be shoppers observed multiple times per week, but I expect such shoppers to be rare. I certainly would not expect to have a balanced panel and no shopper would be observed all 365 days.</p>
<p>I therefore find it reasonable to treat each day of observed data as a single independent cross-section of <span class="math inline">\(L\)</span> transactions generated by an unknown <span class="math inline">\(N \le L\)</span> individuals across <span class="math inline">\(J\)</span> many stores. Aligned sequentially, these form a repeated cross-sections over-time. Each transaction also falls naturally into a cluster—the store where it occurred—that is time-invariant and determined prior to the data being collected.</p>
<p>The model DDD model above can be improved by introducing store effects. These effectively capture experimental assignment and all other time-invariant store-level characteristics. The <span class="math inline">\(dE\)</span> dummy, for example, drops out. The notation can also be cleaned up by condensing the others dummies, emphasizing only variation. The spruced up model is</p>
<span class="math display" id="eq:ddd">\[\begin{equation}
y_{ijt} = \gamma_j + \lambda_t + \phi_0 D_i + \phi_1 D_{ij} + \phi_2 D_{it}+ \phi_3 D_{jt} + \delta_t D_{ijt} + \bm{x&#39;}_{ijt} \bm{\beta} + \epsilon_{ijt}
\tag{1.1}
\end{equation}\]</span>
<p>where <span class="math inline">\(\gamma_j\)</span> now represents store effects, <span class="math inline">\(dS_i \equiv D_i\)</span>, and the remaining dummy variables <span class="math inline">\(D_{ij},~D_{jt},~D_{it},~D_{ijt}\)</span> represent the dimensions along which they vary—<span class="math inline">\(i\)</span> transaction type (SNAP or not), <span class="math inline">\(j\)</span> store experiment group, and <span class="math inline">\(t\)</span> day during DUFB treatment period (August - December). To capture more detail than just the average, <span class="math inline">\(\delta_t\)</span> is allowed to vary by day.</p>
<p><strong>Unobserved Effects</strong></p>
<p>I still do not know what the transaction characteristic variables will be and hence do not know what variables go into <span class="math inline">\(\bm{x&#39;}_{ijt}\)</span>. I do know, however, that without panel data, I have no methods for dealing with unobserved individual effects. That is, some unobserved individual effect <span class="math inline">\(c_i\)</span> likely exists such that <span class="math inline">\(e_{ijt} = c_i + u_{ijt}\)</span> where <span class="math inline">\(\exists t \ni E[\bm{x&#39;}_{ijt}c_i] \ne 0\)</span>. In short, my estimates will be biased due to an omitted variables problem.</p>
<p>I’m am still thinking about how I can capture part of the unobserved individual effect <span class="math inline">\(c_i\)</span>. I am open to suggestions.</p>
<hr />
</div>
<div id="tobit-and-other-hurdle-models" class="section level3 unnumbered">
<h3>Tobit and other Hurdle Models</h3>
<p>Calculating fruit and vegetable expenditures, <span class="math inline">\(y_{ijt}\)</span>, for each transaction will result with a non-trivial amount of zeros. These zeros are not “censored” values in the Heckman selection problem sense. They are genuine zeros aka “corner solution”. But the mechanisms behind the zeros is unknown.</p>
<p><strong>Tobit Model</strong></p>
<p>The Tobit model is agnostic to the economic mechanism generating corner solutions. It is the basic approach when little else is known other than the decision not to purchase fruits and vegetables is resulting in zero-expenditures. The basic structure is</p>
<p><span class="math display">\[
\begin{aligned}
y^* &amp;= x&#39;\beta + u \\
y &amp;= max(0, y^*)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(y^*\)</span> is a latent variable and <span class="math inline">\(y\)</span> is observed. Tobit can be generalized beyond requiring homoskedastic error terms but requires normality. This is important because error terms in repeated cross sectional data are assumed independent <em>not</em> identically distributed. In other words, heteroskedastic. Other than error term specifications, any additive and linear-in-parameters regression can estimated using Tobit. In other words, I can set <span class="math inline">\(y^*\)</span> equal to equation <a href="methods-1.html#eq:ddd">(1.1)</a>.</p>
<p>For details on the likelihood functions, see <span class="citation">Amemiya (<a href="#ref-amemiya_tobit_1984">1984</a>)</span>.</p>
<p><strong>Hurdle and (Naive) Two-Part Models</strong></p>
<p>Hurdle models generally have two parts (i.e. “Double” Hurdle)—a decision-to-buy (participate) and the amount to purchase (consumption) <span class="citation">(Jones <a href="#ref-jones_double-hurdle_1989">1989</a>)</span>. Let <span class="math inline">\(I^* \in {0,1}\)</span> indicate the decision to purchase fruits and vegetables and <span class="math inline">\(y^*\)</span> be the amount of dollars spent. Both are latent variables. Let <span class="math inline">\(y\)</span> be observed expenditures. Formally,</p>
<p><span class="math display" id="eq:dhurdle">\[
\begin{aligned}
I^* &amp;= z&#39;\gamma + v \\
y^* &amp;= x&#39;\beta + u  \\
y   &amp;= I^* \times max(0, y^*) \\
&amp; \phantom{x}\\
(u,v) &amp; \sim N(0,\Omega) \\
\Omega &amp; = {\left ( 
\begin{array}{cc}
  \sigma^2_{u} &amp; \sigma_{uv} \\
  \sigma_{uv} &amp; \sigma^2_{v} 
\end{array}
\right )}
\end{aligned}
\tag{1.2}
\]</span></p>
<p>The <span class="citation">Jones (<a href="#ref-jones_double-hurdle_1989">1989</a>)</span> “Full” Double Hurdle model and the <span class="citation">Cragg (<a href="#ref-cragg_statistical_1971">1971</a>)</span> have the same framework. The distinction is that in the Cragg model assumes no correlation between <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> (i.e. <span class="math inline">\(\sigma_{uv} = 0\)</span>). The likelihood function for the Cragg model is, in other words, a simplification of the Jones model. Formally, the Jones model is</p>
<p><span class="math display" id="eq:lhurdle">\[
\begin{aligned}
L &amp;= \prod_0 
  \left [
    1 - \Phi 
    \left ( 
      \frac{z&#39;\gamma}{\sigma_v},
      \frac{x&#39;\beta}{\sigma_u},
      \rho
    \right ) 
  \right ] \times \\
&amp; \quad ~ \prod_{+} \Phi
  \left [ 
      \frac{ \left ( 
        \frac{z&#39;\gamma}{\sigma_v} + 
        \rho(y^* - x&#39;\beta) \right )}
         {\left ( \sqrt{1 - \rho^2} \right ) } \right ]
\frac{1}{\sigma_u} \phi \left ( \frac{y^* - x&#39;\beta}{\sigma_u} \right )
\end{aligned}
\tag{1.3}
\]</span></p>
<p>Once again, setting the DDD to be <span class="math inline">\(y^*\)</span> is not a problem. The main problem is determining the participation equation <span class="math inline">\(I^*\)</span>. What factors variables participation i.e. the decision-to-buy fruits and vegetables? Variables about individual characteristics would certainly be helpful here but that isn’t possible. There is clearly some mechanism driving consumers to buy or not buy fruits and vegetables. The likeliest candidate is data on <em>other</em> products purchased within a given transaction. The existence of complimentary goods (e.g. olive oil, meats, etc) may increase the likelihood of observing FV purchases within the same trip. The size of the shopping basket likely increases overall chances of FV purchases. Likely day of the week or week of the month, since government benefits and pay schedules may increase the chances of shopping trips in aggregate.</p>
<p>I anticipate estimate both the Jones and Cragg model as a robustness check. But I do not expect <span class="math inline">\(Cov(\sigma_u, \sigma_v) = 0\)</span> given I cannot capture individual effects. Unobserved individual effects likely affect both participation and consumption. In both equations, individual effects are absorbed by the error terms, making them correlated by construction.</p>
<p>I will also estimate a “Naive” Two-Part model, where the participation and consumptions equations are estimate independently from the other (Probit + OLS). Again, just another comparison point.</p>
<p><strong>Multiple Discrete-Continuous Extreme Value Models</strong></p>
<p>The <span class="citation">Bhat (<a href="#ref-bhat_multiple_2005">2005</a>)</span> Multiple Discrete-Continuous Extreme Value (MDCEV) framework allows for choice along a vector of non-mutually exclusive goods. Non-negative consumption is allowed in across all goods.</p>
<p>I will attempt to use a later iteration of the MDCEV model from <span class="citation">Bhat (<a href="#ref-bhat_multiple_2008">2008</a>)</span>. The distinction that interest me is that the Bhat (2008) model allows for price variation across goods and explicitly formulates the Kuhn-Tucker constraints using expenditures. The econometric model is as follows.</p>
<p>Utility from purchasing vector of goods <span class="math inline">\(\bm(x) = (x_1, x_2,...,x_k)\)</span> is defined as</p>
<p><span class="math display">\[
\begin{aligned}
\tilde{U} &amp;= \sum_k \frac{\gamma_k}{\alpha^*_k} \psi(z_k, \epsilon_k)
  \left [ 
    \left (
      \frac{y_k}{\gamma_k p_k} + 1
    \right )^{\alpha_k} - 1
  \right ] \\
\psi(z_k, \epsilon_k) &amp;= exp(z&#39;_k\beta + \epsilon_k)
\\
\sum_k p_k &amp;= Y
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(z_k\)</span> is a vector of attribute variables about product <span class="math inline">\(k\)</span> and of the consumer, <span class="math inline">\(y_k\)</span> is expenditure on product/good <span class="math inline">\(k\)</span>, <span class="math inline">\(p_k\)</span> is the price, and <span class="math inline">\(Y\)</span> is total expenditure on basket of goods <span class="math inline">\(\bm(x)\)</span>. <span class="math inline">\(\epsilon_k\)</span> are idiosyncratic shocks with an extreme-value distribution. To understand the role of <span class="math inline">\(\psi_k\)</span>, <span class="math inline">\(\alpha_k\)</span> and <span class="math inline">\(\gamma_k\)</span>, see <span class="citation">Bhat (<a href="#ref-bhat_multiple_2008">2008</a>)</span> for details.</p>
<p>Using the first good as a reference group, the KT conditions that solve the optimal expenditure problem (the Lagrangian above) are</p>
<p><span class="math display">\[
\begin{aligned}
V_k^* + \sigma \epsilon_k &amp;= V_1^* + \sigma \epsilon_1 \text{ if }
  y_k^* &gt; 0 (k = 2,3,...,K) \\
V_k^* + \sigma \epsilon_k &amp;&lt; V_1^* + \sigma \epsilon_1 \text{ if }
  y_k^* = 0 (k = 2,3,...,K), \text{ where } \\
V_k^* &amp;= \sigma z&#39;_k \beta + \sigma (\alpha_k - 1)
  \text{ln} \left ( \frac{y_k}{\gamma_k p_k} + 1 \right ) - \text{ln} p_k
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(V_k\)</span> is identified only when <span class="math inline">\(\alpha_k\)</span> or <span class="math inline">\(\gamma_k\)</span> is fixed (both terms estimate related “satiation” behaviors). See <span class="citation">Bhat (<a href="#ref-bhat_multiple_2008">2008</a>)</span> (equations 18 and 19) for the Jacobian and closed form expression for the probability of spending <span class="math inline">\(y_k^*\)</span>. Example likelihood function to solve the equation for <span class="math inline">\(i=1,...,L\)</span> transaction (or <span class="math inline">\(N\)</span> individuals) in a given cross-section can be found in <span class="citation">Bhat (<a href="#ref-bhat_multiple_2005">2005</a>)</span> (equation 18) and <span class="citation">Bhat and Sen (<a href="#ref-bhat_household_2006">2006</a>)</span> (equation 8).</p>
<p><strong>Expected Challenges with this Model</strong></p>
<p>Despite the theoretical advantages of the MDCEV framework (i.e. optimization over multiple goods allowing corner solutions), there are a few challenges I anticipate with using the MDCEV framework.</p>
<p>The first is a concern about prices. The most effective way to incorporate price variation is to make the basket of available goods equal to the full universe of observed products. This would likely be huge. The MDCEV framework is flexible enough to do it, but my fear is that it will lead to some difficulties in interpretation. In reality, however, I don’t care as much about expenditure at the product level as much as I do about expenditure on particular types. That is, I care more about spending on FVs versus non-FVs. Therefore, at the simplest level, my vector of possible goods would be just 2. However, how would I price FV versus non-FV? I could construct a price index for just those two groups but it would combine far too many distinct food types to be reasonable. Moving towards something like having between 20 to 40 general food categories seems like better approach. For example, <span class="citation">Harding and Lovenheim (<a href="#ref-harding_effect_2014">2014</a>)</span> estimate the prices for 33 different product groups by using the Stone price index, which depends only on observable price values.</p>
<p>The second concern is programming related. There are no available packages that implement the MDCEV package. I would have to adapt the GAUSS code provided by Bhat on his website in order to get the model running. This isn’t a concern about being able to do it as much as the amount of time it would require to learn/understand GAUSS in order to implement it in R or Python.<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></p>

<hr />
</div>
<div id="regression-discontinuity-rd" class="section level3 unnumbered">
<h3>Regression Discontinuity (RD)</h3>
<p><strong>Work in Progress</strong></p>
<p>I will also perform a secondary Regression Discontinuity (RD) Design analysis.</p>
<p>In the <a href="store-selection-1.html#store-selection-1">Store Selection</a> section, I discussed the construction of the score function <span class="math inline">\(\bm{s} = \widehat{P(\mathbf{D} = 1 | \bm{X}, \bm{N})}\)</span>. The score of each store can be determined via observable data, <span class="math inline">\(s_{j} = \widehat{P(D_{j} = 1|\bm{x}_{j}, n_{j})}\)</span>. These scores, when ordered, produced perfect separation between experimental stores and control stores (see Figure <a href="methods-1.html#fig:score-plot2">1.5</a>).</p>
<p>An RD design requires a <em>running variable</em> where, above some value <span class="math inline">\(c\)</span>, the probability of being assigned to the experimental group is <span class="math inline">\(1\)</span>. Assume I make the score function <span class="math inline">\(\bm{s}\)</span> my running variable such that <span class="math inline">\(D_{j} = \bm{1}[s_{j} \ge c]\)</span>.</p>
<p>In my case, assignment <span class="math inline">\(D_{j}\)</span> is determined by <span class="math inline">\(s_{j}\)</span> by construction. Recall that <span class="math inline">\(s_{j}\)</span> is a function estimated on observable covariates. These are the same observable covariates the company used to determine assignment for a subset of stores. I used a linear probability model to estimate the score function and the estimated model perfectly predicted assignment. I then ordered stores by their score value and selected the next 12 unassigned stores.</p>
<p>This problem is that I do not actually know <span class="math inline">\(c\)</span>. I only know that <span class="math inline">\(c \in (0.50, 0.64)\)</span>. The light gray band in Figure <a href="methods-1.html#fig:score-plot2">1.5</a> displays the possible values of <span class="math inline">\(c\)</span>. The problem, in essence, is that I do not have—and never will have—enough stores, so I’m lacking density around where the separation occurs.</p>
<div class="figure"><span id="fig:score-plot2"></span>
<img src="noriega-prospectus-draft_files/figure-html/score-plot2-1.png" alt="Store Score vs Double Up Assignment with Uncertainty Band (light gray)"  />
<p class="caption">
FIGURE 1.5: Store Score vs Double Up Assignment with Uncertainty Band (light gray)
</p>
</div>
<p>I propose to estimate the RD design using various values of <span class="math inline">\(c\)</span>. The perpetual gap means any model estimate to the left or right of some <span class="math inline">\(c_0 \in (0.50, 0.64)\)</span> will have to be extrapolated up to <span class="math inline">\(c_0\)</span>.</p>
<p><strong>Set-up</strong></p>
<p>The outcome of variable, as before, is <em>the total daily amount of dollars spent on fruits and vegetables per store transaction</em>. I decided on using days as the unit of observation to increase the sample amount of data for estimating. I expect there to be enough transactions per day for this to be possible. The time frame will be August - December (months <span class="math inline">\(8\)</span> - <span class="math inline">\(12\)</span>) of 2016, when the DUFB incentive is place. Only SNAP transactions will be considered and transactions will be pooled. Given that stores may vary in sales volume sold, I may divide by total SNAP dollars spent so that the outcome variable is instead a proportion. In total, there will be <code>11</code> treated (experimental) stores and <code>12</code> control stores.</p>
<p>Let <span class="math inline">\(y_{jt}\)</span> represent the outcome variable where <span class="math inline">\(j=1,...,N\)</span> denotes stores across <span class="math inline">\(t=1,...,T\)</span>. Let <span class="math inline">\(c\)</span> denote the cutoff; <span class="math inline">\(s_{j}\)</span> the score computed for store <span class="math inline">\(j\)</span>; and <span class="math inline">\(D_{j}\)</span> the assignment variable. Each draw (or row) of data for store <span class="math inline">\(j\)</span> is a vector <span class="math inline">\((y_{jt}, s_{j}, D_{j})\)</span> corresponding to a single day. <span class="math inline">\(\lambda_t\)</span> are time effects and <span class="math inline">\(u_{jt}\)</span> is an idiosyncratic store level error term.</p>
<p>The RD model I propose follows the setup of <span class="citation">Lee and Lemieux (<a href="#ref-lee_regression_2010">2010</a>)</span> (section 4.3):</p>
<p><span class="math display">\[y_{jt} = \alpha + \lambda_t + \rho D_{j} + \gamma (s_{j} - c) + \delta D_{j}(s_{j} - c) + u_{jt}\]</span></p>
<p><strong>Expected Results</strong></p>
<p>Plotting RD data and observing a visual gap is standard. The first thing I would do is plot the outcome variable of interest—total daily (fraction of) SNAP dollars spent on fruits and vegetables–against the running variable <span class="math inline">\(s_j\)</span>. A total of <span class="math inline">\(N \times T\)</span> (23 <span class="math inline">\(\times\)</span> 153) data points exists; each value of <span class="math inline">\(s_j,~j=1,...,23\)</span> will contain <span class="math inline">\(T=153\)</span> points.</p>
<p>The graph produced will have more gaps compared to conventional RD graphs. In more conventional RD graphs, each point represents a single value for a single person (e.g. score on an exam), producing more points along the running variable axis. I do not have enough stores to produce enough <span class="math inline">\(s_j\)</span> values for this to be possible. Instead, this RD design plots multiple points per stores, creating a distribution such that the mean (or median) value (with some confidence interval) becomes the fitted values of interested. Estimation wise, this distinction changes very little; <span class="math inline">\(E[y_{jt}|s_{j}, D_{j}]\)</span> effectively fits a mean value to each different store. But graphically, what matters in my RD is the overlap between distributions before and after the cut-off point.</p>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-train_discrete_2009">
<p>Train, Kenneth E. 2009. <em>Discrete Choice Methods with Simulation</em>. Cambridge university press.</p>
</div>
<div id="ref-dube_multiple_2004">
<p>Dubé, Jean-Pierre. 2004. “Multiple Discreteness and Product Differentiation: Demand for Carbonated Soft Drinks.” <em>Marketing Science</em> 23 (1): 66–81.</p>
</div>
<div id="ref-hendel_estimating_1999">
<p>Hendel, Igal. 1999. “Estimating Multiple-Discrete Choice Models: An Application to Computerization Returns.” <em>Review of Economic Studies</em> 66 (2): 423–46.</p>
</div>
<div id="ref-pudney_modelling_1989">
<p>Pudney, Stephen. 1989. “Modelling Individual Choice: The Econometrics of Corners, Kinks and Holes.”</p>
</div>
<div id="ref-humphreys_dealing_2013">
<p>Humphreys, Brad R. 2013. “Dealing with Zeros in Economic Data.” <em>Department of Economics, University of Alberta, Alberta</em>.</p>
</div>
<div id="ref-carlevaro_multiple_2016">
<p>Carlevaro, Fabrizio, Universite ' De Genève, Yves Croissant, and Universite ' De La Réunion. 2016. “Multiple Hurdle Tobit Models in R: The Mhurdle Package.”</p>
</div>
<div id="ref-jones_note_1992">
<p>Jones, Andrew M. 1992. “A Note on Computation of the Double-Hurdle Model with Dependence with an Application to Tobacco Expenditure.” <em>Bulletin of Economic Research</em> 44 (1): 67–74. doi:<a href="https://doi.org/10.1111/\%28ISSN\%291467-8586/issues">10.1111/\%28ISSN\%291467-8586/issues</a>.</p>
</div>
<div id="ref-cragg_statistical_1971">
<p>Cragg, John G. 1971. “Some Statistical Models for Limited Dependent Variables with Application to the Demand for Durable Goods.” <em>Econometrica: Journal of the Econometric Society</em>, 829–44.</p>
</div>
<div id="ref-deaton_statistical_1984">
<p>Deaton, Angus, and Margaret Irish. 1984. “Statistical Models for Zero Expenditures in Household Budgets.” <em>Journal of Public Economics</em> 23 (1-2): 59–80.</p>
</div>
<div id="ref-yen_modeling_1995">
<p>Yen, S. T., and S. J. Su. 1995. “Modeling US Butter Consumption with Zero Observations.” <em>Agricultural and Resource Economics Review (USA)</em>.</p>
</div>
<div id="ref-su_microeconometric_1996">
<p>Su, Shew Jiuan, and Steven T. Yen. 1996. “Microeconometric Models of Infrequently Purchased Goods: An Application to Household Pork Consumption.” <em>Empirical Economics</em> 21 (4): 513–33. doi:<a href="https://doi.org/10.1007/BF01180699">10.1007/BF01180699</a>.</p>
</div>
<div id="ref-newman_double-hurdle_2003">
<p>Newman, Carol, Maeve Henchion, and Alan Matthews. 2003. “A Double-Hurdle Model of Irish Household Expenditure on Prepared Meals.” <em>Applied Economics</em> 35 (9): 1053–61.</p>
</div>
<div id="ref-hay_ordinary_1987">
<p>Hay, Joel W., Robert Leu, and Paul Rohrer. 1987. “Ordinary Least Squares and Sample-Selection Models of Health-Care Demand Monte Carlo Comparison.” <em>Journal of Business &amp; Economic Statistics</em> 5 (4): 499–506. doi:<a href="https://doi.org/10.1080/07350015.1987.10509618">10.1080/07350015.1987.10509618</a>.</p>
</div>
<div id="ref-manning_monte_1987">
<p>Manning, W. G., N. Duan, and W. H. Rogers. 1987. “Monte Carlo Evidence on the Choice Between Sample Selection and Two-Part Models.” <em>Journal of Econometrics</em> 35 (1): 59–82. doi:<a href="https://doi.org/10.1016/0304-4076(87)90081-9">10.1016/0304-4076(87)90081-9</a>.</p>
</div>
<div id="ref-leung_choice_1996">
<p>Leung, Siu Fai, and Shihti Yu. 1996. “On the Choice Between Sample Selection and Two-Part Models.” <em>Journal of Econometrics</em> 72 (12): 197–229. doi:<a href="https://doi.org/10.1016/0304-4076(94)01720-4">10.1016/0304-4076(94)01720-4</a>.</p>
</div>
<div id="ref-dow_choosing_2003">
<p>Dow, William H., and Edward C. Norton. 2003. “Choosing Between and Interpreting the Heckit and Two-Part Models for Corner Solutions.” <em>Health Services &amp; Outcomes Research Methodology; Dordrecht</em> 4 (1): 5–18.</p>
</div>
<div id="ref-madden_sample_2008">
<p>Madden, David. 2008. “Sample Selection Versus Two-Part Models Revisited: The Case of Female Smoking and Drinking.” <em>Journal of Health Economics</em> 27 (2): 300–307. doi:<a href="https://doi.org/10.1016/j.jhealeco.2007.07.001">10.1016/j.jhealeco.2007.07.001</a>.</p>
</div>
<div id="ref-yen_working_1993">
<p>Yen, Steven T. 1993. “Working Wives and Food Away from Home: The Box-Cox Double Hurdle Model.” <em>American Journal of Agricultural Economics</em> 75 (4): 884–95. doi:<a href="https://doi.org/10.2307/1243976">10.2307/1243976</a>.</p>
</div>
<div id="ref-smith_tobit_2003">
<p>Smith, Douglas A., and Robert Brame. 2003. “Tobit Models in Social Science Research Some Limitations and a More General Alternative.” <em>Sociological Methods &amp; Research</em> 31 (3): 364–88.</p>
</div>
<div id="ref-stewart_tobit_2013">
<p>Stewart, Jay. 2013. “Tobit or Not Tobit?” <em>Journal of Economic and Social Measurement</em> 38 (3): 263–90.</p>
</div>
<div id="ref-dubin_econometric_1984">
<p>Dubin, Jeffrey A., and Daniel L. McFadden. 1984. “An Econometric Analysis of Residential Electric Appliance Holdings and Consumption.” <em>Econometrica</em> 52 (2): 345–62. doi:<a href="https://doi.org/10.2307/1911493">10.2307/1911493</a>.</p>
</div>
<div id="ref-bhat_multiple_2005">
<p>Bhat, Chandra R. 2005. “A Multiple Discretecontinuous Extreme Value Model: Formulation and Application to Discretionary Time-Use Decisions.” <em>Transportation Research Part B: Methodological</em> 39 (8): 679–707. doi:<a href="https://doi.org/10.1016/j.trb.2004.08.003">10.1016/j.trb.2004.08.003</a>.</p>
</div>
<div id="ref-wales_estimation_1983">
<p>Wales, T. J., and A. D. Woodland. 1983. “Estimation of Consumer Demand Systems with Binding Non-Negativity Constraints.” <em>Journal of Econometrics</em> 21 (3): 263–85. doi:<a href="https://doi.org/10.1016/0304-4076(83)90046-5">10.1016/0304-4076(83)90046-5</a>.</p>
</div>
<div id="ref-kim_modeling_2002">
<p>Kim, Jaehwan, Greg M. Allenby, and Peter E. Rossi. 2002. “Modeling Consumer Demand for Variety.” <em>Marketing Science</em> 21 (3): 229–50.</p>
</div>
<div id="ref-amemiya_tobit_1984">
<p>Amemiya, Takeshi. 1984. “Tobit Models: A Survey.” <em>Journal of Econometrics</em> 24 (1): 3–61. doi:<a href="https://doi.org/10.1016/0304-4076(84)90074-5">10.1016/0304-4076(84)90074-5</a>.</p>
</div>
<div id="ref-jones_double-hurdle_1989">
<p>Jones, Andrew M. 1989. “A Double-Hurdle Model of Cigarette Consumption.” <em>Journal of Applied Econometrics</em> 4 (1): 23–39.</p>
</div>
<div id="ref-bhat_multiple_2008">
<p>Bhat, Chandra R. 2008. “The Multiple Discrete-Continuous Extreme Value (MDCEV) Model: Role of Utility Function Parameters, Identification Considerations, and Model Extensions.” <em>Transportation Research Part B: Methodological</em>, A tribute to the career of frank koppelman, 42 (3): 274–303. doi:<a href="https://doi.org/10.1016/j.trb.2007.06.002">10.1016/j.trb.2007.06.002</a>.</p>
</div>
<div id="ref-bhat_household_2006">
<p>Bhat, Chandra R., and Sudeshna Sen. 2006. “Household Vehicle Type Holdings and Usage: An Application of the Multiple Discrete-Continuous Extreme Value (MDCEV) Model.” <em>Transportation Research Part B: Methodological</em> 40 (1): 35–53. doi:<a href="https://doi.org/10.1016/j.trb.2005.01.003">10.1016/j.trb.2005.01.003</a>.</p>
</div>
<div id="ref-harding_effect_2014">
<p>Harding, Matthew, and Michael Lovenheim. 2014. “The Effect of Prices on Nutrition: Comparing the Impact of Product- and Nutrient-Specific Taxes,” January.</p>
</div>
<div id="ref-lee_regression_2010">
<p>Lee, David S., and Thomas Lemieux. 2010. “Regression Discontinuity Designs in Economics.” <em>Journal of Economic Literature</em> 48 (2): 281–355. doi:<a href="https://doi.org/10.1257/jel.48.2.281">10.1257/jel.48.2.281</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="10">
<li id="fn10"><p>See <span class="citation">Wooldridge (<a href="#ref-wooldridge_econometric_2010">2010</a>)</span> for more details. I’m assuming familiarity with the DDD model.<a href="methods-1.html#fnref10">↩</a></p></li>
<li id="fn11"><p><span class="citation">Wooldridge (<a href="#ref-wooldridge_econometric_2010">2010</a>)</span> does not appear to differentiate between “Two-Part” models and “Hurdle” models. I will use it following <span class="citation">Humphreys (<a href="#ref-humphreys_dealing_2013">2013</a>)</span> language, which does.<a href="methods-1.html#fnref11">↩</a></p></li>
<li id="fn12"><p>See <span class="citation">García and Labeaga (<a href="#ref-garcia_alternative_1996">1996</a>)</span> and <span class="citation">Aristei, Perali, and Pieroni (<a href="#ref-aristei_cohort_2008">2008</a>)</span> for abstention-style hurdles.<a href="methods-1.html#fnref12">↩</a></p></li>
<li id="fn13"><p>It looks like some folks at the company <a href="http://www.mobilityanalytics.org">Mobility Analytics</a> have started, which is very promising.<a href="methods-1.html#fnref13">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="store-selection-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter-2.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["noriega-prospectus-draft.pdf", "noriega-prospectus-draft.epub", "noriega-prospectus-draft.mobi"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
