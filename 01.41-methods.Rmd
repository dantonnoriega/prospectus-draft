---

### Difference-in-Difference-in-Differences (DDD) {-}

I observe transaction $i$ in store $j$ across $t=1,...,T$ days. Let $y_{ijt}$ be total FV expenditures for transaction $i$ in store $j$ on day $t$. The DDD regression is

$$
\begin{aligned}
y_{ijt} &= \alpha_0 + \alpha_1 dE_j + \alpha_2 dS_i  + \alpha_3 dE_j \cdot dS_i \\& \quad + \theta_1 dP_t + \theta_2 dP_t \cdot dE_j + \theta_3 dP_t \cdot dS_i \\
& \quad + \delta dE_j \cdot dS_i \cdot dP_t + \bm{x'}_{ijt} \bm{\beta} + \lambda_t + \epsilon_{ijt}
\end{aligned}
$$

where $dE_j$ represents store assignment to experimental group, $dS_i$ represents a SNAP or SNAP related transaction (target group), and $dP_t$ represent the treatment period, August - December. $\lambda_t$ captures daily (time) effects and $\bm{x'}_{ijt}$ is a vector of observable characteristics about transaction $i$ in store $j$ on day $t$. The coefficient of interest is $\delta$. $\epsilon_{ijt}$ are idiosyncratic errors at the transaction level. 

Again, I do not observed individuals, only transactions. Yet I think it reasonable to assume that the structure of daily transaction data more closely resembles that of repeated cross-sections than of panel data. Assuming it was possible to link individuals to purchases and build panel data. The same individual would likely observed *sporadically* within in a given month. That is, were this to be panel of the same $N$ individual shoppers across $T$ total days, many---if not most---of those days would have missing data. There would certainly be shoppers observed multiple times per week, but I expect such shoppers to be rare. I certainly would not expect to have a balanced panel and no shopper would be observed all 365 days.

I therefore find it reasonable to treat each day of observed data as a single independent cross-section of $K$ transactions generated by an unknown $N \le K$ individuals across $J$ many stores. Aligned sequentially, these form a repeated cross-sections over-time. Each transaction also falls naturally into a cluster---the store where it occurred---that is time-invariant and determined prior to the data being collected.

The model DDD model above can be improved by introducing store effects. These effectively capture experimental assignment and all other time-invariant store-level characteristics. The $dE$ dummy, for example, drops out. The notation can also be cleaned up by condensing the others dummies, emphasizing only variation. The spruced up model is

\begin{equation}
y_{ijt} = \gamma_j + \lambda_t + \phi_0 D_i + \phi_1 D_{ij} + \phi_2 D_{it}+ \phi_3 D_{jt} + \delta_t D_{ijt} + \bm{x'}_{ijt} \bm{\beta} + \epsilon_{ijt}
(\#eq:ddd)
\end{equation}

where $\gamma_j$ now represents store effects, $dS_i \equiv D_i$, and the remaining dummy variables $D_{ij},~D_{jt},~D_{it},~D_{ijt}$ represent the dimensions along which they vary---$i$ transaction type (SNAP or not), $j$ store experiment group, and $t$ day during DUFB treatment period (August - December). To capture more detail than just the average, $\delta_t$ is allowed to vary by day.

**Unobserved Effects**

I still do not know what the transaction characteristic variables will be and hence do not know what variables go into $\bm{x'}_{ijt}$. I do know, however, that without panel data, I have no methods for dealing with unobserved individual effects. That is, some unobserved individual effect $c_i$ likely exists such that $e_{ijt} = c_i + u_{ijt}$ where $\exists t \ni E[\bm{x'}_{ijt}c_i] \ne 0$. In short, my estimates will be biased due to an omitted variables problem.

I'm am still thinking about how I can capture part of the unobserved individual effect $c_i$. I am open to suggestions. 

---

### Tobit and other Hurdle Models {-}

Calculating fruit and vegetable expenditures, $y_{ijt}$, for each transaction will result with a non-trivial amount of zeros. These zeros are not "censored" values in the Heckman selection problem sense. They are genuine zeros aka "corner solution". But the mechanisms behind the zeros is unknown.

**Tobit Model**

The Tobit model is agnostic to the economic mechanism generating corner solutions. It is the    basic approach when little else is known other than the decision not to purchase fruits and vegetables is resulting in zero-expenditures. The basic structure is

$$
\begin{aligned}
y^* &= x'\beta + u \\
y &= max(0, y^*)
\end{aligned}
$$

where $y^*$ is a latent variable and $y$ is observed. Tobit can be generalized beyond requiring homoskedastic error terms but requires normality. This is important because error terms in repeated cross sectional data are assumed independent *not* identically distributed. In other words, heteroskedastic. Other than error term specifications, any additive and linear-in-parameters regression can estimated using Tobit. In other words, I can set $y^*$ equal to equation \@ref(eq:ddd).

For details on the likelihood functions, see @amemiya_tobit_1984.

**Hurdle and (Naive) Two-Part Models**

Hurdle models generally have two parts (i.e. "Double" Hurdle)---a decision-to-buy (participate) and the amount to purchase (consumption) [@jones_double-hurdle_1989]. Let $I^* \in {0,1}$ indicate the decision to purchase fruits and vegetables and $y^*$ be the amount of dollars spent. Both are latent variables. Let $y$ be observed expenditures. Formally,

$$
\begin{aligned}
I^* &= z'\gamma + v \\
y^* &= x'\beta + u  \\
y   &= I^* \times max(0, y^*) \\
& \phantom{x}\\
(u,v) & \sim N(0,\Omega) \\
\Omega & = {\left ( 
\begin{array}{cc}
  \sigma^2_{u} & \sigma_{uv} \\
  \sigma_{uv} & \sigma^2_{v} 
\end{array}
\right )}
\end{aligned}
(\#eq:dhurdle)
$$

The @jones_double-hurdle_1989 "Full" Double Hurdle model and the @cragg_statistical_1971 have the same framework. The distinction is that in the Cragg model assumes no correlation between $u$ and $v$ (i.e. $\sigma_{uv} = 0$). The likelihood function for the Cragg model is, in other words, a simplification of the Jones model. Formally, the Jones model is

$$
\begin{aligned}
L &= \prod_0 
  \left [
    1 - \Phi 
    \left ( 
      \frac{z'\gamma}{\sigma_v},
      \frac{x'\beta}{\sigma_u},
      \rho
    \right ) 
  \right ] \times \\
& \quad ~ \prod_{+} \Phi
  \left [ 
      \frac{ \left ( 
        \frac{z'\gamma}{\sigma_v} + 
        \rho(y^* - x'\beta) \right )}
         {\left ( \sqrt{1 - \rho^2} \right ) } \right ]
\frac{1}{\sigma_u} \phi \left ( \frac{y^* - x'\beta}{\sigma_u} \right )
\end{aligned}
(\#eq:lhurdle)
$$

Once again, setting the DDD to be $y^*$ is not a problem. The main problem is determining the participation equation $I^*$. What factors variables participation i.e. the decision-to-buy fruits and vegetables? Variables about individual characteristics would certainly be helpful here but that isn't possible. There is clearly some mechanism driving consumers to buy or not buy fruits and vegetables. The likeliest candidate is data on *other* products purchased within a given transaction. The existence of complimentary goods (e.g. olive oil, meats, etc) may increase the likelihood of observing FV purchases within the same trip. The size of the shopping basket likely increases overall chances of FV purchases. Likely day of the week or week of the month, since government benefits and pay schedules may increase the chances of shopping trips in aggregate.

I anticipate estimate both the Jones and Cragg model as a robustness check. But I do not expect $Cov(\sigma_u, \sigma_v) = 0$ given I cannot capture individual effects. Unobserved individual effects likely affect both participation and consumption. In both equations, individual effects are absorbed by the error terms, making them correlated by construction.

I will also estimate a "Naive" Two-Part model, where the participation and consumptions equations are estimate independently from the other (Probit + OLS). Again, just another comparison point. 

**Multiple Discrete-Continuous Extreme Value Models**

 


